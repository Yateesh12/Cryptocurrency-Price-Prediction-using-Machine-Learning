# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IHhOxlZLSQPYAQsWu82o8daPUmH_0hH6
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score

# Load the dataset
hazel_df = pd.read_csv("btc.csv")  # Change to the correct file path

# Display the first few rows of the DataFrame
print(hazel_df.head())

# Feature selection
# Drop 'crypto' and 'date' as they are not numeric features
all_features = hazel_df.drop(columns=['Crypto', 'Date', 'Close'])  # Assuming we want to predict 'close'
target_feature = (hazel_df['Close'].shift(-1) > hazel_df['Close']).astype(int)  # Binary target: 1 if price goes up, else 0
all_features.head()

# Dataset preprocessing
# Ensure all features are numeric
x = all_features.values.astype(float)  # Returns a numpy array of type float
min_max_scaler = MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
scaled_features = pd.DataFrame(x_scaled, columns=all_features.columns)  # Retain column names
scaled_features.head()

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(scaled_features, target_feature, test_size=0.25, random_state=40)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

# Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# K-fold cross-validation
kfold = KFold(n_splits=10, random_state=None)  # k=10, split the data into 10 equal parts
result_logistic = cross_val_score(model, scaled_features, target_feature, cv=kfold, scoring='accuracy')
print('The overall score for Logistic Regression classifier is:', round(result_logistic.mean() * 100, 2))

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt=".1f", cmap='summer')
plt.title('Logistic Regression Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Print classification metrics
print('\n--------------- Logistic Regression Classification Report ---------------\n')
print(classification_report(y_test, y_pred))

# Additional metrics
print('Micro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='micro')))
print('Micro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='micro')))
print('Micro F1-score: {:.4f}\n'.format(f1_score(y_test, y_pred, average='micro')))

print('Macro Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='macro')))
print('Macro Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='macro')))
print('Macro F1-score: {:.4f}\n'.format(f1_score(y_test, y_pred, average='macro')))

print('Weighted Precision: {:.4f}'.format(precision_score(y_test, y_pred, average='weighted')))
print('Weighted Recall: {:.4f}'.format(recall_score(y_test, y_pred, average='weighted')))
print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, y_pred, average='weighted')))

#KNN
from sklearn.model_selection import KFold #for K-fold cross validation
from sklearn.model_selection import cross_val_score #score evaluation
from sklearn.model_selection import cross_val_predict #prediction
from sklearn.metrics import confusion_matrix #for confusion matrix
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors = 25)
model.fit(X_train,y_train)
dt_knn=model.predict(X_test)
kfold = KFold(n_splits=10, random_state=None) # k=10, split the data into 10 equal parts=
result_knn=cross_val_score(model,scaled_features,target_feature,cv=kfold,scoring='accuracy')
print('The overall score for K Nearest Neighbors Classifier is:',round(result_knn.mean()*100,2))
y_pred = cross_val_predict(model,scaled_features,target_feature,cv=10)
sns.heatmap(confusion_matrix(dt_knn,y_test),annot=True,fmt=".1f",cmap='summer')
plt.title('KNN Confusion_matrix')


#KNN fold accuracy visualizer
_result_knn=[r*100 for r in result_knn]
plt.plot(_result_knn)
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('K-NN fold accuracy visualizer')


from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score
print('Micro Precision: {:.4f}'.format(precision_score(y_test, dt_knn, average='micro')))
print('Micro Recall: {:.4f}'.format(recall_score(y_test, dt_knn, average='micro')))
print('Micro F1-score: {:.4f}\n'.format(f1_score(y_test, dt_knn, average='micro')))

print('Macro Precision: {:.4f}'.format(precision_score(y_test, dt_knn, average='macro')))
print('Macro Recall: {:.4f}'.format(recall_score(y_test, dt_knn, average='macro')))
print('Macro F1-score: {:.4f}\n'.format(f1_score(y_test, dt_knn, average='macro')))

print('Weighted Precision: {:.4f}'.format(precision_score(y_test, dt_knn, average='weighted')))
print('Weighted Recall: {:.4f}'.format(recall_score(y_test, dt_knn, average='weighted')))
print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, dt_knn, average='weighted')))

print('\n--------------- K-Nearest Neighbour Classification Report ---------------\n')
print(classification_report(y_test, dt_knn))
#print('---------------------- K-NN ----------------------') # unnecessary fancy styling

#Naive bayes
from sklearn.naive_bayes import GaussianNB
model= GaussianNB()
model.fit(X_train,y_train)
gnb_pred=model.predict(X_test)
kfold = KFold(n_splits=10, random_state=None) # k=10, split the data into 10 equal parts
result_gnb=cross_val_score(model,scaled_features,target_feature,cv=10,scoring='accuracy')
print('The overall score for Gaussian Naive Bayes classifier is:',round(result_gnb.mean()*100,2))
y_pred = cross_val_predict(model,scaled_features,target_feature,cv=10)
sns.heatmap(confusion_matrix(gnb_pred,y_test),annot=True,fmt=".1f",cmap='summer')
plt.title('Naive Bayes Confusion_matrix')


#Naive bayes fold accuracy visualizer
_result_gnb=[r*100 for r in result_gnb]
plt.plot(_result_gnb)
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('Accuracy')
plt.title('Naive bayes fold accuracy visualizer')


from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score
print('Micro Precision: {:.4f}'.format(precision_score(y_test, gnb_pred, average='micro')))
print('Micro Recall: {:.4f}'.format(recall_score(y_test, gnb_pred, average='micro')))
print('Micro F1-score: {:.4f}\n'.format(f1_score(y_test, gnb_pred, average='micro')))

print('Macro Precision: {:.4f}'.format(precision_score(y_test, gnb_pred, average='macro')))
print('Macro Recall: {:.4f}'.format(recall_score(y_test, gnb_pred, average='macro')))
print('Macro F1-score: {:.4f}\n'.format(f1_score(y_test, gnb_pred, average='macro')))


print('Weighted Precision: {:.4f}'.format(precision_score(y_test, gnb_pred, average='weighted')))
print('Weighted Recall: {:.4f}'.format(recall_score(y_test, gnb_pred, average='weighted')))
print('Weighted F1-score: {:.4f}'.format(f1_score(y_test, gnb_pred, average='weighted')))

print('\n---------------Naive Bayes Classification Report ---------------\n')
print(classification_report(y_test, gnb_pred))
#print('---------------------- Naive Bayes ----------------------') # unnecessary fancy styling